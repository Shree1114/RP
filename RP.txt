1.Write a R program to take input from the user (name and age) and display the values. Also print           the version of R installation.
CODE:
name <- readline(prompt = "Enter your name: ")
age <- as.integer(readline(prompt = "Enter your age: "))
cat("Your name is", name, "and your age is", age, "\n")
2.Write a R program to get the details of the objects in memory.
CODE:
x <- 1:10
y <- rnorm(100)
z <- "Hello World"
data <- data.frame(A = 1:5, B = c("a", "b", "c", "d", "e"))
obj.names <- ls()
for (obj.name in obj.names) {
  obj.size <- object.size(get(obj.name))
  cat(paste("Object name:", obj.name, "Object size:", obj.size, "\n"))
}
3.	Write a R program to create a sequence of numbers from 20 to 50 and find the mean of numbers from 20 to 60 and sum of numbers from 51 to 91.
CODE:
seq1 <- 20:50
seq2 <- 20:60
mean1 <- mean(seq2)
seq3 <- 51:91
sum1 <- sum(seq3)
cat("Sequence 1: ", seq1, "\n")
cat("Mean of sequence 2: ", mean1, "\n")
cat("Sum of sequence 3: ", sum1, "\n")
4.	Write a R program to create a vector which contains 10 random integer values between -50 and +50.
CODE:
set.seed(123)
rand_vec <- sample(-50:50, 10, replace = TRUE)
cat("Random Vector: ", rand_vec, "\n")

5.	Write a R program to get the first 10 Fibonacci numbers.
CODE:
fib <- function(n) {
  if (n <= 1) {
    return(n)
  } else {
    return(fib(n-1) + fib(n-2))
  }
}
fib_seq <- numeric(10)
for (i in 1:10) {
  fib_seq[i] <- fib(i)
}
cat("The first 10 Fibonacci numbers are: ", fib_seq, "\n")

6.	Write a R program to get all prime numbers up to a given number (based on the sieve of Eratosthenes).
CODE:
sieve_of_eratosthenes <- function(n) {
  nums <- 2:n  
  for (i in 2:sqrt(n)) {
    nums <- nums[nums == i | nums %% i != 0]
  }
  return(nums)
}
n <- 50
primes <- sieve_of_eratosthenes(n)
cat("All prime numbers up to", n, "are:", primes, "\n")

7.	Write a R program to print the numbers from 1 to 100 and print "Fizz" for multiples of 3, print "Buzz" for multiples of 5, and print "FizzBuzz" for multiples of both.
CODE:
for (i in 1:100) {
  if (i %% 3 == 0 & i %% 5 == 0) {
    cat("FizzBuzz\n")
  } else if (i %% 3 == 0) {
    cat("Fizz\n")
  } else if (i %% 5 == 0) {
    cat("Buzz\n")
  } else {
    cat(i, "\n")
  }
}
8.	Write a R program to extract first 10 english letter in lower case and last 10 letters in upper case and extract letters between 22nd to 24th letters in upper case.
CODE:
first_letters <- letters[1:10]
cat("First 10 letters in lower case: ", first_letters, "\n")
last_letters <- toupper(letters[17:26])
cat("Last 10 letters in upper case: ", last_letters, "\n")
mid_letters <- toupper(letters[22:24])
cat("Letters between 22nd and 24th letters in upper case: ", mid_letters, "\n")
1.	Write a R program to find the factors of a given number.
CODE:
find_factors <- function(num) {
  factors <- c()
  for (i in 1:num) {
	if (num %% i == 0) {
  	factors <- c(factors, i)
	}
  }
  return(factors)
}
num <- 20
factors <- find_factors(num)
cat(paste("The factors of", num, "are:", factors))

2.	Write a R program to find the maximum and the minimum value of a given vector.
CODE:
vec <- c(10, 50, 30, 70, 20, 90)
max_val <- max(vec)
cat("Maximum value in vector is:", max_val, "\n")
min_val <- min(vec)
cat("Minimum value in vector is:", min_val, "\n")
3.	Write a R program to get the unique elements of a given string and unique numbers of vector.
CODE:
my_string <- "hello world"
unique_chars <- unique(strsplit(my_string, "")[[1]])
print(unique_chars)

my_vector <- c(1, 2, 3, 4, 3, 2, 1)
unique_numbers <- unique(my_vector)
print(unique_numbers)

4.	Write a R program to create three vectors a,b,c with 3 integers. Combine the three vectors to become a 3×3 matrix where each column represents a vector. Print the content of the matrix.
CODE:
a <- c(1,2,3)
b <- c(4,5,6)
c <- c(7,8,9)
matrix <- cbind(a,b,c)
print(matrix)
5.	Write a R program to create a list of random numbers in normal distribution and count occurrences of each value.
CODE:
set.seed(123)
random_numbers <- rnorm(100, mean = 0, sd = 1)

occurrences <- table(random_numbers)
print(occurrences)

6.	Write a R program to read the .csv file and display the content.
CODE:
setwd("C:/programfile/user/onedrive/r ")
my_data <- read.csv("sport.csv")
print(my_data)

7.	Write a R program to create three vectors numeric data, character data and logical data. Display the content of the vectors and their type.
	CODE:
numeric_vector <- c(1, 2, 3, 4, 5)
char_vector <- c("apple", "banana", "cherry", "date", "elderberry")
logical_vector <- c(TRUE, FALSE, TRUE, TRUE, FALSE)

cat("Numeric vector:", numeric_vector, "\n")
cat("Character vector:", char_vector, "\n")
cat("Logical vector:", logical_vector, "\n")

cat("Data type of numeric vector:", typeof(numeric_vector), "\n")
cat("Data type of character vector:", typeof(char_vector), "\n")
cat("Data type of logical vector:", typeof(logical_vector), "\n")
8.	Write a R program to create a 5 x 4 matrix , 3 x 3 matrix with labels and fill the matrix by rows and 2 × 2 matrix with labels and fill the matrix by columns.
CODE:
mat1 <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20), nrow=5, ncol=4, byrow=TRUE)
rownames(mat1) <- c("Row1", "Row2", "Row3", "Row4", "Row5")
colnames(mat1) <- c("Col1", "Col2", "Col3", "Col4")
print(mat1)

mat2 <- matrix(c(1,2,3,4,5,6,7,8,9), nrow=3, ncol=3, byrow=TRUE)
rownames(mat2) <- c("RowA", "RowB", "RowC")
colnames(mat2) <- c("ColX", "ColY", "ColZ")
print(mat2)

mat3 <- matrix(c(1,2,3,4), nrow=2, ncol=2, byrow=FALSE)
rownames(mat3) <- c("Row1", "Row2")
colnames(mat3) <- c("ColA", "ColB")
print(mat3)

1.	Write a R program to create an array, passing in a vector of values and a vector of dimensions. Also provide names for each dimension.
CODE:
values <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
dims <- c(3, 3)
dim_names <- list(c("Rows 1", "Rows 2", "Rows 3"), c("Columns 1", "Columns 2", "Columns 3"))
my_array <- array(values, dim = dims, dimnames = dim_names)
print(my_array)
2.	Write a R program to create an array with three columns, three rows, and two "tables", taking two vectors as input to the array. Print the array.
CODE:
    vec1 <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
	vec2 <- c(10, 11, 12, 13, 14, 15, 16, 17, 18)
	arr <- array(c(vec1, vec2), dim = c(3, 3, 2))
	print(arr)
3.	Write a R program to create a list of elements using vectors, matrices and a functions. Print the content of the list.
CODE:
vec <- c(1, 2, 3)
mat <- matrix(c(4, 5, 6, 7, 8, 9), nrow = 2)
myfun <- function(x) {
  x^2
}
mylist <- list(vec, mat, myfun)
print(mylist)

4.	Write a R program to draw an empty plot and an empty plot specify the axes limits of the graphic
    CODE:
	plot.new()
    plot.new(xlim = c(0, 20), ylim = c(0, 20))

5.	Write a R program to create an array of two 3x3 matrices each with 3 rows and 3 columns from two given two vectors. Print the second row of the second matrix of the array and the element in the 3rd row and 3rd column of the 1st matrix.
CODE:
print("Two vectors of different lengths:")
v1 =  c(1,3,4,5)
v2 =  c(10,11,12,13,14,15)
print(v1)
print(v2)
result = array(c(v1,v2),dim = c(3,3,2))
print("New array:")
print(result)
print("The second row of the second matrix of the array:")
print(result[2,,2])
print("The element in the 3rd row and 3rd column of the 1st matrix:")
print(result[3,3,1])

6.	Write a R program to combine three arrays so that the first row of the first array is followed by the first row of the second array and then first row of the third array.
CODE:
arr1 <- array(1:9, dim = c(3, 3))
arr2 <- array(10:18, dim = c(3, 3))
arr3 <- array(19:27, dim = c(3, 3))
combined_arr <- rbind(arr1[1,], arr2[1,], arr3[1,])
print(combined_arr)
7.	Write a R program to create an array using four given columns, three given rows, and two given tables and display the content of the array.
	CODE:
v1 <- c(1, 2, 3)
v2 <- c(4, 5, 6)
v3 <- c(7, 8, 9)
v4 <- c(10, 11, 12)
mat1 <- cbind(v1, v2, v3, v4)
mat2 <- matrix(c(13:15), nrow = 1)
mat3 <- matrix(c(16:18), nrow = 1)
arr1 <- array(c(mat1, mat2, mat3), dim = c(3, 4, 2))
print(arr1)

8.	Write a R program to create a two-dimensional 5x3 array of sequence of even integers greater than 50.
CODE:
arr1 <- array(seq(from = 50, by = 2, length.out = 15), dim = c(5, 3))
print(arr1)

1.	Create below data frame 
exam_data = data.frame( 
name = c('Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'), 
score = c(12.5, 9, 16.5, 12, 9, 20, 14.5, 13.5, 8, 19), 
attempts = c(1, 3, 2, 3, 2, 3, 1, 1, 2, 1), 
qualify = c('yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes') 
) 
a. Write a R program to extract 3rd and 5th rows with 1st and 3rd columns from a given data frame 
b. Write a R program to add a new column named country in a given data frame 
Country<-c("USA","USA","USA","USA","UK","USA","USA","India","USA","USA") 
c. Write a R program to add new row(s) to an existing data frame 
new_exam_data = data.frame(name = c('Robert', 'Sophia'),score = c(10.5, 9), attempts = c(1, 3),qualify = c('yes', 'no')) 
d. Write a R program to sort a given data frame by name and score 
e. Write a R program to save the information of a data frame in a file and display the information of the file.
CODE:
exam_data = data.frame( 
name = c('Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'), 
score = c(12.5, 9, 16.5, 12, 9, 20, 14.5, 13.5, 8, 19), 
attempts = c(1, 3, 2, 3, 2, 3, 1, 1, 2, 1), 
qualify = c('yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes') 
)

#subdiv1
exam_data[c(3, 5), c(1, 3)]


#subdiv2
Country <- c("USA", "USA", "USA", "USA", "UK", "USA", "USA", "India", "USA", "USA",)
exam_data$country <- Country
#sub_div_3
new_exam_data <- data.frame(name = c('Robert', 'Sophia'), score = c(10.5, 9), attempts = c(1, 3), qualify = c('yes', 'no'))
exam_data <- rbind(exam_data, new_exam_data)
#subdiv4
exam_data <- exam_data[order(exam_data$name, exam_data$score), ]
#subdiv5
write.csv(exam_data, file = "exam_data.csv", row.names = FALSE)
exam_data_from_file <- read.csv("exam_data.csv")
exam_data_from_file

2.	Write a R program to call the (built-in) dataset air quality. Check whether it is a data frame or not? Order the entire data frame by the first and second column. remove the variables 'Solar.R' and 'Wind' and display the data frame.    
CODE:
data(airquality)
class(airquality)
airquality <- airquality[order(airquality$Month, airquality$Day),]
airquality <- airquality[, -c(1, 4)]
airquality
3.	Write a R program to create a factor corresponding to height of women data set , which inbuild in R, contains height and weights for a sample of women.
CODE:
data(women)
height <- women$height
height_factor <- cut(height, breaks = c(50, 55, 60, 65, 70, 75))
levels(height_factor)

4.	Write a R program to extract the five of the levels of factor created from a random sample from the LETTERS (Part of the base R distribution.)    
CODE:
set.seed(123)
letters_sample <- sample(LETTERS, 20, replace=TRUE)
letters_factor <- factor(letters_sample)
five_levels <- levels(letters_factor)[1:5]
five_levels
5.	Iris dataset is a very famous dataset in almost all data mining, machine learning courses, and it has been an R build-in dataset. The dataset consists of 50 samples from each of three species of Iris flowers (Iris setosa, Iris virginica and Iris versicolor). Four features(variables) were measured from each sample, they are the length and the width of sepal and petal, in centimetres. Perform the following EDA steps . 
(i)Find dimension, Structure, Summary statistics, Standard Deviation of all features. 
(ii)Find mean and standard deviation of features groped by three species of Iris flowers (Iris setosa, Iris virginica and Iris versicolor) 
(iii)Find quantile value of sepal width and length 
(iV)create new data frame named iris1 which have a new column name Sepal.Length.Cate that categorizes “Sepal.Length” by quantile 
(V) Average value of numerical varialbes by two categorical variables: Species and Sepal.Length.Cate: 
(vi) Average mean value of numerical varialbes by Species and Sepal.Length.Cate 
(vii)Create Pivot Table based on Species and Sepal.Length.Cate.
	CODE:
data(iris)

#subdiv1
dim(iris)
str(iris)
summary(iris)
apply(iris[, 1:4], 2, sd)

#subdiv2
aggregate(iris[, 1:4], by = list(Species = iris$Species), FUN = mean)
aggregate(iris[, 1:4], by = list(Species = iris$Species), FUN = sd)

#subdiv3
quantile(iris$Sepal.Length)
quantile(iris$Sepal.Width)

#subdiv4
iris1 <- iris
iris1$Sepal.Length.Cate <- cut(iris1$Sepal.Length, breaks = quantile(iris1$Sepal.Length), include.lowest = TRUE)
head(iris1)

#subdiv5
aggregate(iris1[, 1:4], by = list(Species = iris1$Species, Sepal.Length.Cate = iris1$Sepal.Length.Cate), FUN = mean)

#subdiv6
library(dplyr)
iris1 %>% 
  group_by(Species, Sepal.Length.Cate) %>% 
  summarise(across(everything(), mean))

#subdiv7
library(tidyr)
pivot_table <- pivot_wider(iris1, names_from = Sepal.Length.Cate, values_from = c(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width))
pivot_table %>% 
  group_by(Species) %>% 
  summarise(across(everything(), mean))

6.	Randomly Sample the iris dataset such as 80% data for training and 20% for test and create Logistics regression with train data, use species as target and petals width and length as feature variables , Predict the probability of the model using test data, Create Confusion matrix for above test model     CODE: 
data(iris)
set.seed(123)
trainIndex <- sample(1:nrow(iris), 0.8*nrow(iris))
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]

library(nnet)
irisLogReg <- multinom(Species ~ Petal.Length + Petal.Width, data=trainData)

testData$predicted <- predict(irisLogReg, newdata=testData, type="prob")

library(caret)
confusionMatrix(data=testData$Species, reference=testData$predicted)

OUTPUT:
7.	(i)Write suitable R code to compute the mean, median, mode of the following values c (90, 50, 70, 80, 70, 60, 20, 30, 80, 90, 20) (ii) Write R code to find 2nd highest and 3rd Lowest value of above problem.     
CODE:
#subdiv1
x <- c(90, 50, 70, 80, 70, 60, 20, 30, 80, 90, 20)
mean(x)
median(x)

install.packages("DescTools") 
library(DescTools)
Mode(x)

#subdiv2
x <- c(90, 50, 70, 80, 70, 60, 20, 30, 80, 90, 20)
sort(x, decreasing = TRUE)[2]
sort(x)[3]
8.	Explore the air quality dataset. It contains daily air quality measurements from New York during a period of five months: • Ozone: mean ozone concentration (ppb), • Solar.R: solar radiation (Langley), • Wind: average wind speed (mph), • Temp: maximum daily temperature in degrees Fahrenheit, • Month: numeric month (May=5, June=6, and so on), • Day: numeric day of the month (1-31). i. Compute the mean temperature (don’t use build in function) 
ii. Extract the first five rows from air quality.
iii. Extract all columns from air quality except Temp and Wind 
iv. Which was the coldest day during the period?
v. How many days was the wind speed greater than 17 mph? 
	CODE:
#subdiv1
data(airquality)
mean_temp <- sum(airquality$Temp)/length(airquality$Temp)
mean_temp

#subdiv2
data(airquality)
airquality[1:5,]

#subdiv3
data(airquality)
airquality[, !(names(airquality) %in% c("Temp", "Wind"))]

#subdiv4
data(airquality)
coldest_day <- airquality[which.min(airquality$Temp),]
coldest_day

#subdiv5
data(airquality)
n_days_windy <- sum(airquality$Wind > 17, na.rm = TRUE)
n_days_windy

1.	Explore the air quality dataset. It contains daily air quality measurements from New York during a period of five months: • Ozone: mean ozone concentration (ppb), • Solar.R: solar radiation (Langley), • Wind: average wind speed (mph), • Temp: maximum daily temperature in degrees Fahrenheit, • Month: numeric month (May=5, June=6, and so on),• Day: numeric day of the month (1-31). 
(i)Get the Summary Statistics of air quality dataset
 (ii)Melt airquality data set and display as a long – format data?
 (iii)Melt airquality data and specify month and day to be “ID variables”? 
(iv)Cast the molten airquality data set with respect to month and date features
 (v) Use cast function appropriately and compute the average of Ozone, Solar.R , Wind and temperature per month?
CODE:
#subdiv1
data(airquality)
summary(airquality)
#subdiv2
library(reshape2)
melted_data <- melt(airquality)
melted_data
#subdiv3
melted_data <- melt(airquality, id.vars = c("Month", "Day"))
melted_data
#subdiv4
casted_data <- dcast(melted_data, Month + Day ~

2.	i)Find any missing values(na) in features and drop the missing values if its less than 10% else replace that with mean of that feature. 
(ii) Apply a linear regression algorithm using Least Squares Method on “Ozone” and “Solar.R” (iii)Plot Scatter plot between Ozone and Solar and add regression line created by above model      
CODE:
#subdiv1
data(airquality)
missing_values <- colSums(is.na(airquality))
percent_missing <- missing_values / nrow(airquality) * 100
ifelse(percent_missing < 10, airquality <- na.omit(airquality), )
ifelse(percent_missing >= 10, airquality[is.na(airquality)] <- mean(airquality, na.rm = TRUE), )
#subdiv2
data(airquality)
model <- lm(Ozone ~ Solar.R, data = airquality)
summary(model)
#subdiv3
data(airquality)
model <- lm(Ozone ~ Solar.R, data = airquality)
plot(Ozone ~ Solar.R, data = airquality)
abline(model, col = "red")
3.	Load dataset named ChickWeight, ( i).Order the data frame, in ascending order by feature name “weight” grouped by feature “diet” and Extract the last 6 records from order data frame. (ii).a Perform melting function based on “Chick", "Time", "Diet" features as ID variables b. Perform cast function to display the mean value of weight grouped by Diet c. Perform cast function to display the mode of weight grouped by Diet  
CODE:
#subdiv1
data(ChickWeight)
ordered_data <- ChickWeight[order(ChickWeight$weight), ]
tail(ordered_data, 6)
#subdiv2
data(ChickWeight)
melted_data <- melt(ChickWeight, id.vars = c("Chick", "Time", "Diet"))
head(melted_data)
#subdiv3
data(ChickWeight)
melted_data <- melt(ChickWeight, id.vars = c("Chick", "Time", "Diet"))
mean_weight_by_diet <- cast(melted_data, Diet ~ variable, mean)
mean_weight_by_diet
#divc
data(ChickWeight)
melted_data <- melt(ChickWeight, id.vars = c("Chick", "Time", "Diet"))
get_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
mode_weight_by_diet <- cast(melted_data, Diet ~ variable, get_mode)
mode_weight_by_diet
4.	a. Create Box plot for “weight” grouped by “Diet”
 b. Create a Histogram for “weight” features belong to Diet- 1 category 
c. Create Scatter plot for “weight” vs “Time” grouped by Diet    
CODE:
#subdiv1
library(ggplot2)
data(ChickWeight)
ggplot(ChickWeight, aes(x = factor(Diet), y = weight)) + 
  geom_boxplot() + 
  labs(x = "Diet", y = "Weight") + 
  ggtitle("Weight Distribution by Diet")
#subdiv2
ggplot(ChickWeight[ChickWeight$Diet == 1, ], aes(x = weight)) + 
  geom_histogram(binwidth = 10, color = "black", fill = "white") + 
  labs(x = "Weight", y = "Count") + 
  ggtitle("Weight Distribution for Diet-1")
#subdiv3
ggplot(ChickWeight, aes(x = Time, y = weight, color = factor(Diet))) + 
  geom_point() + 
  labs(x = "Time", y = "Weight") + 
  ggtitle("Weight vs Time by Diet")
5.	a. Create Box plot for “weight” grouped by “Diet” 
b. Create a Histogram for “weight” features belong to Diet- 1 category
 c. Create Scatter plot for “weight” vs “Time” grouped by Diet.
	CODE:
#sub_div_1
library(ggplot2)
data(ChickWeight)
ggplot(ChickWeight, aes(x = factor(Diet), y = weight)) + 
  geom_boxplot() + 
  labs(x = "Diet", y = "Weight") + 
  ggtitle("Weight Distribution by Diet")
#subdiv2
ggplot(subset(ChickWeight, Diet == 1), aes(x = weight)) + 
  geom_histogram(binwidth = 10, color = "black", fill = "white") + 
  labs(x = "Weight", y = "Count") + 
  ggtitle("Weight Distribution for Diet-1")
#subdiv3
ggplot(ChickWeight, aes(x = Time, y = weight, color = factor(Diet))) + 
  geom_point() + 
  labs(x = "Time", y = "Weight") + 
  ggtitle("Weight vs Time by Diet")

6.	For this exercise, use the (built-in) dataset Titanic. a. Draw a Bar chart to show details of “Survived” on the Titanic based on passenger Class b. Modify the above plot based on gender of people who survived c. Draw histogram plot to show distribution of feature “Age”
CODE:
#subdiv1
data(Titanic)
library(ggplot2)
ggplot(data = as.data.frame(Titanic), aes(x = Class, y = Freq, fill = Survived)) + 
  geom_bar(stat = "identity", position = "dodge") + 
  labs(x = "Passenger Class", y = "Count", fill = "Survived") + 
  ggtitle("Titanic Survival by Passenger Class")
#subdiv2
data(Titanic)
ggplot(data = as.data.frame(Titanic), aes(x = Class, y = Freq, fill = Sex)) + 
  geom_bar(stat = "identity", position = "dodge") + 
  labs(x = "Passenger Class", y = "Count", fill = "Gender") + 
  ggtitle("Titanic Survival by Gender and Class") + 
  theme(legend.position = "top")
#subdiv3
data(Titanic)
ggplot(data = as.data.frame(Titanic), aes(x = Age, fill = Survived)) + 
  geom_histogram(binwidth = 5, alpha = 0.7, position = "identity") + 
  labs(x = "Age", y = "Count", fill = "Survived") + 
  ggtitle("Age Distribution on Titanic") + 
  theme(legend.position = "top")
7.	Explore the USArrests dataset, contains the number of arrests for murder, assault, and rape for each of the 50 states in 1973. It also contains the percentage of people in the state who live in an urban area.
(i)	a. Explore the summary of Data set, like number of Features and its type. Find the number of records for each feature. Print the statistical feature of data 
b. Print the state which saw the largest total number of rape
 c. Print the states with the max & min crime rates for murder
 (ii)        a. Find the correlation among the features
 b. Print the states which have assault arrests more than median of the country
 c. Print the states are in the bottom 25% of murder 
iii)	 a. Create a histogram and density plot of murder arrests by US stat
b. Create the plot that shows the relationship between murder arrest rate and proportion of the population that is urbanised by state. Then enrich the chart by adding assault 	arrest rates (by colouring the points from blue (low) to red (high)). 
		c. Draw a bar graph to show the murder rate for each of the 50 states.
	CODE:
#subdiv1
data(USArrests)
summary(USArrests)
str(USArrests)
data(USArrests)
USArrests[which.max(USArrests$Rape), "State"]
data(USArrests)
max_murder_states <- USArrests[which.max(USArrests$Murder), "State"]
min_murder_states <- USArrests[which.min(USArrests$Murder), "State"]
cat("State(s) with maximum murder rate:", max_murder_states, "\n")
cat("State(s) with minimum murder rate:", min_murder_states, "\n")
#subdiv2
data(USArrests)
cor(USArrests)
data(USArrests)
median_assault <- median(USArrests$Assault)
USArrests[USArrests$Assault > median_assault, "State"]
data(USArrests)
bottom25_murder <- quantile(USArrests$Murder, 0.25)
USArrests[USArrests$Murder < bottom25_murder, "State"]
#subdiv3
data(USArrests)
hist(USArrests$Murder, main = "Histogram of Murder Arrests by US State", xlab = "Murder Arrests")
lines(density(USArrests$Murder), col = "red")
data(USArrests)
library(ggplot2)
ggplot(USArrests, aes(UrbanPop, Murder)) +
  geom_point(aes(colour = Assault), size = 3) +
  scale_colour_gradient(low = "blue", high = "red") +
  labs(title = "Relationship between Murder Arrest Rate and Proportion of Urban Population by State", x = "Proportion of Urban Population", y = "Murder Arrests")
. a. Create a data frame based on below table.


Month	1	2	3	4	5	6	7	8	9	10	11	12
Spends	1000	4000	5000	4500	3000	4000	9000	11000	15000	12000	7000	3000
Sales	9914	40487	54324	50044	34719	42551	94871	118914	158484	131348	78504	36284

b. Create a regression model for that data frame table to show the amount of sales(Sales) based on the how much the company spends (Spends) in advertising
c. Predict the Sales if Spend=13500
CODE:
#subdiv1
df <- data.frame(
  Month = 1:12,
  Spends = c(1000, 4000, 5000, 4500, 3000, 4000, 9000, 11000, 15000, 12000, 7000, 3000),
  Sales = c(9914, 40487, 54324, 50044, 34719, 42551, 94871, 118914, 158484, 131348, 78504, 36284)
)
df
#subdiv2
model <- lm(Sales ~ Spends, data = df)
summary(model)
#subdiv3
new_data <- data.frame(Spends = 13500)
prediction <- predict(model, newdata = new_data)
prediction




